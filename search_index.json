[["index.html", "VOSviewer: putting research into context Chapter 1 Introduction", " VOSviewer: putting research into context Rutger de Jong, Dennis Bus 2023-02-03 Chapter 1 Introduction VOSviewer is an application to provide overviews of scientific landscapes by clustering related publications. It can help you find more accurate keywords for searching, collaboration partners, seminal papers and knowledge gaps. Item Description Name VOSviewer Cost Free download Likely uses Discovery; Storytelling Benefits Creating overviews of research topics; insight to the working of other tools What intelligence Clustering algorithm; Natural Language Processing; Layout algorithm URL https://www.vosviewer.com "],["theory.html", "Chapter 2 VOSviewer Introduction and Theory", " Chapter 2 VOSviewer Introduction and Theory We decided to kick off our series on searching with artificial intelligence with an old faithful companion: VOSviewer. The application was actually created to make visualizations of bibliometric networks by Leiden’s Centre for Science and Technology (CWTS). This may seem like a strange choice: VOSviewer does not do any searching per se, you have to extract your search results and import them yourself. However, some techniques used in VOSviewer are also implemented in other solutions, and the information the tool provides can be very helpful to get a better understanding of your field of research, especially if you are starting out on a topic that is new for you as a researcher. "],["how-it-works.html", "2.1 How it works", " 2.1 How it works At the basis of the VOSviewer is the visualization of similarities (N. J. V. Eck and Waltman 2007) (N. J. van Eck and Waltman 2010). The objects – articles, journals, organizations, authors or terms – are located relative to each other in such a way that the distance between two objects is an approximate measure of their similarity within the set. For example if we would look at a data set of articles about food, a topic such as food processing will form a cluster of its own, while a topic such as nutritional value might form another cluster at a distance from the processing. However, there will also be some instances where the food processing method has a direct influence on the nutritional value: these articles will be found in between the two clusters or at the edge of either cluster, depending on the main topic of the article. So how exactly does VOS know if something is similar? Within the program we can choose from several options to base the similarity upon, depending on the data set and type of analysis we want to do: · Co-authorship, to build collaboration networks and find partners for research projects · Co-occurrence (based on the documents terms occuring together), to discover the best search keywords and define popularity, age and impact of topics · Citation analysis (direct citation), to discover seminal papers that everyone refers to · Bibliographic coupling (based on the number of shared references), to find articles with a common knowledge base · Co-citations (the number of times articles are cited together), to find complementary articles The information VOSviewer uses is all contained within the set of articles you start from. So let’s say we want to find the most popular articles within a topic. We will start by downloading all of these articles including their citation information. We see documents as similar if they refer to or are cited by the same other documents (similarity because they link each other, the direction is not important). Thus we can calculate for all pairs of documents in our set how similar document i is to document j. VOS uses the following formula for this: \\[ similarity_{ij}=\\cfrac{2n_{documents}citations_{shared\\_ij}}{citations_{total_i}citations_{total_j}}=\\cfrac{relation\\_between\\_items}{normalisation\\_factor} \\] So how do we go from a high dimensional similarity- matrix - score to a visual representation? The really difficult task of VOS is to map all of these documents on a two dimensional chart, so that the distance between the documents is related to the inverse of their similarity (they are displayed closer to each other if they are more similar), while at the same time the documents should not overlap in the visualization. As the sets get bigger you may imagine how the complexity builds and the exact position becomes more of an estimation, but still provides us with a clear picture of overlap within linked articles. The distance between fully unlinked articles or clusters of articles is less clear: in fact they should be as far from the other documents they are not (indirectly) linked to as possible. img TIP: Layout is created by optimizing the possibilities. The computer algorithm in use tries all combinations until it finds a semi-optimal presentation. As the algorithm starts at a random position, the results may differ if you run the layout multiple times. To prevent this, set a specific number (not 0) for random seed. This option can be found in the analysis tab, under the ‘Advanced parameters’ of the Layout section. After the mapping to x,y-coordinates on a map, VOSviewer goes one step further and also indicates to us some clusters of highly related terms visualized with colours. These clusters make the maps so easy to interprete (and sell in presentations to funders). A common way in AI to find clusters is by density-based clustering. In other words, where there are many points, there is most likely a clustering of related points. There is no set number of clusters in this technique, but you have to set tresholds (which you can adjust in the program) for the document similarity so the algorithm knows when to neglect a document for a specific cluster. It works as follows: img If the clustering seems off, you can play with the thresholds to provide a better view. Overall clustering works best if the set is not completely uniform. In case you see just one big circle, it could well be that your set consists of very uniform topics or highly unrelated topics. In VOSviewer you will notice that some items are visualized in between items of other colors. The principles mentioned above do still apply, but the real clustering uses the similarity network in the background. While the visualization is 2-dimensional, this similarity network has many dimensions. References "],["who-can-benefit-from-vosviewer.html", "2.2 Who can benefit from VOSviewer?", " 2.2 Who can benefit from VOSviewer? We see some clear use cases for the VOSviewer software in several roles within the university. Click the links to see an example of how one can use the technique described. For some techniques we will create a short tutorial later this month. 2.2.1 Principal Investigator Most likely you are already an expert in the topic at hand. However, sometimes you need to visualize your knowledge in order to get funding for example, where the funder wants to see collaboration partners or the impact of your output within the field. Or you have a research question where you need to know what has not yet been researched in depth, what topics are hot or what search terms (also known as article search engine optimization) make your work as visible as possible. · Collaboration maps (author similarity) · Article overview of the field (based on citations) · Topic overview (based on search terms) 2.2.2 PhD As a PhD you usually start out fresh on a new line of research when you enter university. You want to catch up quickly to the knowledge base of the professors and need field overviews. You also want to know what specific topics and keywords are of interest at the moment so you can focus your search and research interests. · Article overview of the field (based on citations) · Topic overview (based on search terms) · Journal maps =&gt; waar moet ik publiceren 2.2.3 Policy makers You need to be able to support research policy. Possibly you want to tell stories about how your researchers collaborate (internally and externally), how your organization is mentioned in news outlets and whether the publication output matches the goals set for the research vision. · Collaboration maps (author similarity) · Topic overview (based on search terms) · Overlays (ook bij andere mogelijkheden dan term maps) =Map en networkfiles meegeven, citatielijst publicaties If you are interested in all possibilities of the VOSviewer software, check out the other chapters for examples and information on how to use a diversity of databases to get the best results. Another good starting point to discover all of VOSviewers possibilities is the AIDA booklet. "],["limitations.html", "2.3 Limitations", " 2.3 Limitations Based upon the examples, the technical basis and our experience as librarians, we have identified the following limitations you have to take into account while working with VOSviewer: - Large dataset needed for most evaluations (at least 100-200 items) =&gt; alleen tot zijn recht als je een grotere set hebt, anders statistisch niet relevant - The parameters and dataset you provide determine what the visualization will look like. It is important to know that the software can be used mainly for qualitative indications and not so much for quantitative measurement. It is also necessary to be very specific while working with VOSviewer: o How did I obtain my data (search query, database, date, number of results) o What parameters did I use to create my maps (counting method, excluded keywords, number of occurrences/citations, etc.) o Did I change visualization parameters? o Write down what you see in the different clusters and what this tells you o Why did I make these choices? o It may be difficult to assess if you are not an expert in the field yet. Always ask an expert (supervisor for a Ph.D. for example) to have a look at the map and help with the analysis. In my experience they immediately see patterns and are usually quite surprised by the results. o The software is not automatically updated; check the VOSviewer website regularly as new functionality is rolled out frequently. o Non-standard databases/materials without DOI need additional work to be used. o Author analysis: the authors are defined by name, not by Orcid. This means it is unusable in fields dominated by Chinese authors. o Term extraction is based on English language/grammar. The algorithm used for natural language processing is not suitable for other languages. In the examples we will explain how to convert text to English. Be aware that using VOSviewer is an iterative process. Most likely your first tries will give you some information to improve your search or visualization. "],["theory-disclaimer.html", "2.4 Disclaimer", " 2.4 Disclaimer In this series we look at new technology to help with literature research. We are not fulltime researchers or programmers and are open to suggestions to improve the contents of these blogs. If you want to share your story/research, or want to help out by providing us your research topic as example, that would be highly appreciated. Please contact Rutger de Jong or Dennis Bus for more information. "],["howto.html", "Chapter 3 How to and use cases (some basic modes of VOS)", " Chapter 3 How to and use cases (some basic modes of VOS) The VOSviewer has been officially introduced in an article in Scientometrics in 2010 (N. J. van Eck and Waltman 2010) . As the researchers ask you to cite this publication when you are using the VOSviewer in scholarly publications, there is a lot information on the formal usage. Of course we have to do a little meta research into the scholarly uses of the software. The following topics will guide you through some analyses you can use with VOSviewer. At the same time they will introduce several techniques for gathering data. However, it is usually no problem to switch out data gathering techniques, so you might want to look at other examples. The table below gives an overview of the topics and techniques covered. Chapter Analysis Techniques covered Sources Topic overview Basic text analysis that can be used for gathering keywords, getting a field overview and finding knowledge gaps text analysis Web of Science Seminal papers Analysis of citation links to find the most important articles to read in order to understand the field Bibliographic network based on articles Web of Science Seminal papers 2 Analysis of citation links to find the most important articles to read in order to understand the field Bibliographic network based on articles Library Catalogue; DOI Collaboration Network analysis to see which authors are important in the field and might be useful for collaboration Bibliographic network based on authors thesaurus; filtering Journals Network analysis to see what journals you should follow and where you want to publish Network based on sources Topic analysis Text analysis with scoring files to investigate clusters more closely text analysis; text conversion; translation; scoring files Nexis Uni References "],["installation.html", "3.1 Installation", " 3.1 Installation To start with the tutorials you need a version of VOSviewer. Please download the most recent version from https://www.vosviewer.com/download for your operating system and unzip the download. No installation is necessary: - for Windows you can run the .exe application file - for Mac OS X and other systems, you should use the JAR file To run VOSviewer, Java 8 or newer has to be installed. If it has not been installed, please download Java from the Software Center or install directly via https://www.java.com . "],["howto-topics.html", "3.2 Creating an overview of topics", " 3.2 Creating an overview of topics VOSviewer has a text analysis that lets you create topic overviews from a text file, for example of the title and abstract in the search results of a generic query. Let’s assume we look for potatoes, then VOSviewer will extract terms such as the different potato families, pests, genetic modification, et cetera from the overall text. By connecting the documents with the same terms (co-occurrence clustering), it will cluster terms in topics that you will be able to recognize, for example pesticides and food processing.The occurrence and age of the term give us information on the research that has been done into this topic. In this case we think it may be interesting to check if there are common topics for which VOSviewer is used a lot. Therefore we do not do a generic search, but use the initial paper on VOSviewer as starting point. Everyone who uses VOSviewer in a publication, has to refer to that specific article. For your own research you may want to do a basic search in Web of Science and then continue with the export in step 5. Go to Web of Science Make sure the search settings are set to ‘Search in: Web of Science Core Collection’. The Core Collection is slightly smaller than all access to Web of Science, however it is the only collection with all information on article citations and therefore the best one to use for VOSviewer. img We choose ‘Cited References’ and enter the DOI from the article as search term. img Select the correct article and click ‘See results’. We now have 3.635 citing articles. Once you are doing this for a real research, please write down the number of results and copy the query link for your reference. img Click on ‘Export’ and choose ‘Tab Delimited File’. Fill out the tab as follows: img TIP: you have to export in sets of 500 articles in this mode. So for this set we need 8 export files. Save the files in their own project directory together with the info on the search query. Now open VOSViewer, click ‘Create’ and choose ‘Create a map based on text data’. img Choose ‘Read data from bibliographic database files’ (there are many options here, including the ability to enter a list of doi identifiers and some limited search engine capabilities; in practice the database files created here are the most powerful source). In the next window choose ‘Web of Science’ and select all of our files by clicking the first and last while holding down the shift button. Click next when you are done. Select to use terms from both the title and the abstract. Leave the checkmarks as they are and click next. img VOSviewer now extracts all terms from the title and abstract. Internally it uses a natural language processing AI to extract noun phrases (combinations of a noun with dependents, for example in ‘medical unit’ ‘medical’ is dependent upon the head noun ‘unit’). Next it will try to combine multiple and single phrases (‘medical units’). This technique only works in English as the algorithm does not know how to deal with other grammar. As it is based on grammar, the AI can’t connect abbreviations to written out terms. The next question is about binary counting. This means per document a term will be counted as either in the document or not. As a term may be mentioned a lot in a single document, binary counting is usually the preferred setting. The minimum number of occurrences makes the difference between a too detailed map and a map you can use for visualization purposes. You may loose some very specific words, but I try to get the number of results down to 1000-2000. Choose next. img Leave number of terms as is and click next. VOSviewer will now display a list of all terms together with a relevancy ranking.The relevancy ranking tries to find out if a term has a common or specific meaning. It does so by checking the co-occurrence patterns. If a phrase is only mentioned a lot in the introductory part of articles for example, it will be less relevant than a phrase that occurs all over the text. You can choose to leave a word out by unchecking the box if you thing it is of no use. img For this quick analysis we simply click finish. We now get our first basic overview of the citing articles. img You may notice there are three clusters. Two big ones and one smaller, less defined cluster. To get some insight, we note down the largest keywords from each cluster: red: approach, process, challenge, context, model, environment, state, systematic literature review – seems to be on applications of the VOSviewer methodology for innovation green: journal, keyword, country, citation, reference, university – seems to be on the specific use for ranking research(ers) and organizations blue: originality value, co-citation, bibliographic coupling, bibliometric overview – not so clear cut, likely about research on methodologies for scientrometry. Personally I look at the results and think the clustering is a bit off. I can see many terms on environmental issues in the red cluster that may be a cluster on their own. Remember: clustering and visualization is a qualitative and not a quantitave analysis. The choices we have made for including articles, terms, etc. are all shown in the results. To improve my map, I choose to change the clustering so my environmental part is split of. To do this, go to the analysis tab and change the clustering parameters. Here I set resolution from 1 to 1.20 and updated the map. From the map I would now conclude there are four clusters which an expert could describe. I see research on using the VOSviewer methods for literature reviews and overviews for innovation and policies (green), applications for finding models/approaches in mainly the environmental sciences (blue), use in ranking of journals, countries and universities (red) and what looks like basic research for scientometric methods (yellow). In these cases it usually helps to check with an expert in the field. In this specific analysis there may be less clear boundaries as we did not start from a general search but from articles referring to VOSviewer. TIP: Sometimes the phrases are hard to read because they are overlapping. This may be solved by changing the display parameters to attraction=1 and repulsion=0 To see what research is hot at the moment, we can use the publication information from our map. Switch to the ‘Overlay visualization’ tab and make sure the scores on the right are set to ‘Avg. pub.’ (meaning average date of publication). Below the visualization you will notice a bar with a scale for the average publication year. The size of a phrase is determined by the number of publications, the color is the average age. Thus something that is large and blue, has been researched a lot in the past. You will notice that the pandemic has crept up as relatively new term (yellow) with still a small number of publications judging by the size of the dot: are there chances in this subtopic? Why is there such a large connection to country? (tip: check the term pandemic via a filter in your Web of Science query) Medicine is relatively blue and large, so the use of VOSviewer for rankings in this field may be something that has been researched in-depth already. img With a density visualization (last tab) we can find the most important areas of research - at least if those terms are not all from the same papers. In this case VOSviewer seems to be mainly in use for ranking, with another focus point on the strategic – overview - use (concepts, state, approaches, challenges). img "],["howto-paper.html", "3.3 Finding the seminal papers in the field", " 3.3 Finding the seminal papers in the field How do we define what are the most important articles in a specific field? First of all, we start from a selected set of articles that define our field well. For this demonstration we will use the articles from the previous exercise that are somehow connected to VOSviewer. (Please note, it works better with a specific topic, however these articles are bound by an interest in science mapping) It is important that we do have a broad set of articles here. VOSviewer works solely with the documents within your set and the linkage (citation-reference) between these documents. Limiting your research set to for example the last 5 years, will mean that you will only find important articles in the field that were written within these 5 years (also note: recent articles are unlikely to be cited on a large scale so realistically the articles from 3-5 years ago will pop-up). TIP: There are several options for clustering articles. In order to find seminal articles, we use citation linking as base (which articles are the most referred to in this set). For other purposes we may use bibliographic coupling, where we look at the references articles share and are thus able to find very similar articles. The articles that are truly groundbreaking within a field, commonly known as seminal papers, will be the ones that are referred to most often by other articles within the set, as they are essential to understanding the theory. This is different from sorting your results for citations in a database: within VOSviewer you only look at articles from the field, from your selection. So an article that is important to another field, or that has general importance, will not automatically show up. But an article with relatively few overall citations that is referred to a lot in the set, will. Again the clustering algorithm used in VOSviewer will ensure that similar publications (based on the references) are shown close together. Go to VOSviewer and click on the Create button. This time we want to ‘Create a map based on bibliographic data’. We start with ‘Read data from bibliographic files’ and use the same set as in the previous text map. We now have a screen with many options for analysis. Have a look as these can all be used to visualize specific information such as collaborations, what universities are working on a specific topic, which journals are best to publish in etc. As we want to know the seminal papers (within the set!) we choose the option ‘Citation’ and go for an analysis on ‘Documents’. (if you need to know what journals are popular, or which authors to contact, you can choose one of the other units of analysis) Next we are asked to choose a threshold value for the inclusion of an article. A seminal paper will have quite a few citations, so I suggest not to set this value too low. The number of citations is in this case taken from the total number of citations within the source, not the citations within the set. I opted for 20 citations as threshold here. I leave the number of documents as is. If the number is very large (above 1,000) I would recommend lowering it. The next screen gives a clear view of the differences in links (within the set that was selected based on the threshold!) and citations (total number). At the bottom is for example an article by Van der Maaten that has 1190 citations, but no links within the set. In other words, it most likely is not of interest if you are doing scientometrics research (as our set was based of a scientometrics article as common link between the publications). You can ignore these unlinked documents and don’t have to uncheck them manually, as the next question is about their inclusion. Click ‘Yes’ to leave them out. img Our map now looks like this: img You can see the links by articles, but by default the visualization focuses on the total number of citations for the dot size of an article. You can change this in the right menu by choosing ‘Links’. (Another option is normalized citations: this is normalized by publication year as older publications have had more citation possibilities). img Hovering over an article will give you its basic information. If a DOI is available, clicking on the dot will get you to the article. The clusters are a bit more over the place in this analysis. That may be because some of the clusters were of interest to many articles. For example, the grey cluster Cobo belongs to, is all about bibliometric tools. The yellow cluster is about history. The brown cluster about using scientometrics in safety research. "],["howto-papers2.html", "3.4 Finding seminal papers: beyond Web of Science", " 3.4 Finding seminal papers: beyond Web of Science Most analyses with VOSviewer are done with Web of Science as data provider. However, the program has many more options for other data providers available. For example the databases LENS (open database; containing many OA articles), Scopus, Dimensions and PubMed from files, while Semantic Scholar, the new scholarly search engine/API OpenAlex and Crossref can be used to ingest article metadata automatically from within VOSviewer. In fact, with some labor, you can use any source in VOSviewer. To get the most out of it though, it is best to use a source that also tracks citations in order to do the basic bibliometric analyses. Nowadays publishers can use the Crossref database to track citations, so in many cases an export with DOIs from any type of database will be enough. 3.4.1 Using the DOI as base With the Digital Object Identifier (DOI) any scholarly database can be used easily within VOSviewer as long as it indexes DOI. As most international research articles have a DOI (Dutch languages publications and more localized fields such as law usually do not have a DOI), we can use this to our advantage. In this example we will use the library Catalogue as source. Go to https://catalogue.leidenuniv.nl and search for “literature review method” OR ”systematic review method” filter the selection to document type ‘Articles’. Unfortunately the Catalogue limits our results to 50 per page (you can set the number of results per page at the bottom of each page). This means we have to export sets per 50. For this example I will download the first 10 pages by clicking the select box at the top of the page and then choose ‘Export to Excel’ from the menu underneath the three dots. img As file type we choose XLSX and then download all 10 pages subsequently by going to the next page (at the bottom of the page) and repeating the procedure. img We will now copy all of our Excels to their own directory and then we open a new file in Excel. Go to the ‘Data’ ribbon, click on ‘Get Data’=&gt;’From File’=&gt;’From Folder’ img Choose your directory and click ‘Combine’-&gt;’Combine &amp; Load’ in the next screen. img Click ‘Sheet0’ and then ‘OK’. img All of our results are now combined into one big table. The DOI can be found in the column ‘Identifier’, unfortunately together with the ISSN and other identifiers such as the Lucris-ID from our own repository. We will copy this whole column to a new sheet on our Excel. With the values selected go to the ‘Data’ ribbon and click ‘Text to Columns’. Please note not all articles have a DOI! img Choose ‘Delimited’ and choose the semicolon and tab as delimiter. Click Finish img Paste the resulting columns (A; B; C; etc.) underneath each other, so column 1 is filled with all the information (2500 item) and identifiers. Now select the column, go to the ribbon ‘Insert’ and choose ‘Insert Table’. img Click on the triangle on the right and let’s filter our column by the word ‘doi’. img We now have 475 dois which we will select and paste onto another sheet in our Excel. On this sheet do a find and replace (ctrl+f) and replace all ’doi: ’. img Click ‘File’ in the ribbon. Choose for ‘Export’-&gt;’Change File Type’ and go for .csv, tab delimited or another text based format. img Now open VOSviewer. Click ‘Create’=&gt;’Create a Map Based on Bibliographic Data’=&gt;’Download through API’-&gt;DOI and select your file. img Click ‘Next’ and it will download the data through the Crossref API. This may take a while. Again we see a little data loss as only 469 dois could be found (possibly there were duplicates in the set).Click ‘Next’ to choose a map type to create. Of course we are interested to see if the citations are now really in the set. Choose ‘Citations’ as coupling and ‘Documents’ as base. Follow the steps shown previously. Again we now have a map of topics. The first thing to notice: there are not many connected articles. Does this have to do with our citations being incorrect? No, always think about your database. In this case we used the Library Catalogue which is a very able Discovery Engine that in some cases uses information from the fulltext or elaborate abstracts. This means we see methodology chapters of articles as well. We would have done better to restrict the search to for example the title or choose other words. A tool such as VOSviewer can also be a great help in finding out these systematic errors in your search query. "],["journals.html", "3.5 Journal analysis with LENS", " 3.5 Journal analysis with LENS A popular use for VOSviewer is using it to find the best possible journals to publish your research or journals you might want to follow to keep up with the field. If you have a specific topic, it may not always be clear what journal best suits your research. Sending it to the wrong journal might give you a rejection note that your research does not fit the journal profile or - if they do accept - might not lead to the visibility within the research community you hoped for. A Nature editor once warned us that publishing in their journal might be bad if you have something that is of limited interest to the wider community as it might be seen as to experimental or even completely overlooked by peers. In this tutorial we have chosen to find out what journals might be of interest for industrial ecology, a subfield of the environmental sciences. As environmental sciences are relatively new and multidisciplinary, journals from this field may not all be available in Web of Science. This is why we use an alternate scholarly database that indexes a broader collection of journals: LENS. LENS is a vary capable database as it indexes a large amount of scholarly works fulltext and uses artificial intelligence (formerly integrated in Microsoft Academic) to complement the information with document type, topic, et cetera. Go to https://www.lens.org and choose for searching within scholarly works. As keywords we use “circular econom*” OR “industrial ecology” OR “life cycle anal*” which gives us around 15k results. As Document Type we select ‘Journal Article’ from the left menu, leaving us with around 12k articles. img To export all results, we need to create an account at LENS. If you limit the search by specifying (topic, a more strict keyword, time range) you can export 1,000 items without account. With the account I have exported all data as CSV. To do so, go to the small ‘Export button’ underneath the top navigation bar that says ‘Scholarly Works’ (this database has so many options that it may be hard to find). As parameters you can use something like the screenshot: img If there is a large number of articles, LENS will send you an email to download the CSV. This usually takes just a few minutes. Go to VOSviewer and choose Create -&gt; ‘Create a map based on bibliographic data’. In the next screen choose ‘Read data from bibliographic database files, select the tab ’Lens’ and use your downloaded CSV. In the next screen we choose to analyze by Citations and Sources (in our case journals as we have articles published in journals). This way we will see connections between the journals. The next screen asks us how many documents should be minimally in each source. We leave it at 5 for now to give a broad spectrum, but for a large set you can increase this number as you see fit. Click finish to create the visualization. You will now see a map that is dominated by two large journals containing many articles in the field: ‘Russian journal of occupational health and industrial ecology’ and the ‘Journal of industrial ecology’. This is to be expected as we are searching all fields: all articles from journals with ‘industrial ecology’ in the name will be in our search. If this proofs problematic for your search, limit the search to title and abstract or similar fields. Zooming in gives us a much better overview with quite a lot of specific clusters due to the generic keywords we used. Have a look at the items in the left bar to see what clusters there are. Some noteworthy are: brown with the ‘Russian journal of occupational health and industrial ecology’, which seems to be mainly about radiation and nuclear aspects. blue with the ‘Journal of industrial ecology’ which seems to have a clear focus on general aspects, business and economics. This seems to be in accordance to the journals own words: ‘publishes sustainability and circular economy research which considers the relationship between the environment and the socio-economic system’. red, which is highly focused on chemical aspects and includes journals about catalysis. Hovering over a specific journal will give you citation links between the clusters (both ways). Thus you will notice that for example the communication between the socio-economic cluster in blue to the red chemistry cluster is very little. While the red cluster does cite a lot with clusters about production or health hazards. Considering these aspects might help you find the right cluster for your specific article. 10. Once you have an idea of where to find your journal within the clusters, it is time to focus on which journal might be the fit for you. Go to the tab ‘Overlay visualization’ in VOSviewer. With the average publication year, you can see the newer - up and coming - journals. However, if we change the visualization to use the average normalized citation, we can see what journal is most popular (avoiding the word impact as popular does not give an opinion on quality) with our specific search terms. For example, we can see that the Journal of industrial ecology is quite average in number of citations at 0.97. The Russian journal that also had a big output has 0.08 as avg. norm. citation. Resources, Conservation and Recycling in the same cluster as the ‘Journal of industrial ecology’ scores a 2.04, which means it is a little more popular if it fits your specific research. (In the image blue means a low number of average citations, while yellow is a high number of average citations.) img The size of each circle gives the number of articles within our set that has been published in said journal. The larger the circle, the more the journal focuses on this type of research (which means you have a bigger chance of publishing there). Of course we encourage you not to look only at this analysis. Check out the website of the journal and its focus. And check out the possibilities for Open Access you have at the journal via Journal Browser "],["collab.html", "3.6 Collaboration overview (including thesaurus)", " 3.6 Collaboration overview (including thesaurus) Creating overviews with the Author as linking pin can be beneficial for several reasons. For researchers it may help find colleagues to collaborate with as they are already doing similar research or get people that may introduce you through their network. Especially when you need to tender for a large grant, this can be really helpful (note: you can also use the affiliation as base to find where the research is done). For policy makers this analysis may help in visualizing collaborations within and outside of your institution, as these collaborations are often described in multi year plans. For this analysis we will be looking at internal collaborations within Leiden University. As we start from journal articles, where authors from multiple universities may have contributed, we need to do some additional steps with the data from Web of Science to exclude the non-Leiden authors. For this we use a Python script. If you want to follow along, you can copy the code at the top right of the code box. We also use a thesaurus in this chapter. With a thesaurus you can tell VOSviewer that some terms are similar (or in our case authors) so they will be analysed as one. This chapter contains some advanced techniques such as the thesaurus and working with Web of Science data in Python. Those parts can be skipped if you just want to know about creating basic overviews We start by downloading all Leiden University articles in the last 5 years from Web of Science. For this go to Web of Science, as filter choose ‘Affiliation’ with ‘LEIDEN UNIVERSITY’ as value. Set the time range to last 5 years. Export the records as tab delimited files (500 at a time) and save these files to a new directory. We will now create a Python script to filter out the non-Leiden authors. At the top of our Python file we will import the Python libraries needed to do the transformation: import pandas as pd #for working with the data in our tab delimited files import os #for accessing the data files The first step is to load all data from the exported files into the Pandas framework: frames = [] file_dir = &#39;leiden_university&#39; #choose the directory where the exports are in, relative to your Python file for filename in os.listdir(file_dir): frames.append(pd.read_csv(file_dir +&quot;/&quot;+ filename, sep=&quot;\\t&quot;, header=0)) all_articles = pd.concat(frames, ignore_index=True) We know all of our affiliation information is in a column called ‘C1’ (example: [Zananiri, Sary] Leiden Univ, LUCL, Leiden, Netherlands; [Zananiri, Sary] Leiden Univ, NINO, Leiden, Netherlands), while the authors are in a column called AU (example: Zananiri, S) and AF (example: Zananiry, Sary). Let’s process the columns based on the information in C1, and take as premisse that all affiliations containing ‘leiden’ are ok (technically this may include a very minor number of authors from companies based in Leiden, but affiliation information can be quite difficult as affiliations noted as Sterrewacht Leiden also mean the university). authors = [] #to keep track of all different authors all_articles = all_articles.reset_index() for ind, row in all_articles.iterrows(): line = row[&#39;C1&#39;] institution_lines = line.split(&quot;[&quot;) author_initials = &quot;&quot; author_full = &quot;&quot; institution_aff = &quot;&quot; for institution_line in institution_lines: line_parts = institution_line.split(&quot;]&quot;) if len(line_parts)&gt;1: if line_parts[1].lower().find(&#39;leiden&#39;)&gt;=0: # we consider it internal names = line_parts[0].split(&quot;;&quot;) for name in names: name_parts = name.split(&quot;,&quot;) if len(name_parts)&gt;1: first_name = name_parts[1] last_name = name_parts[0] initials = &quot;&quot; init_parts = name_parts[1].split(&quot; &quot;) for init_part in init_parts: initials = initials + init_part[:1] + &quot;.&quot; if len(author_full)==0: author_full = last_name +&quot;, &quot;+first_name author_initials = last_name + &quot;, &quot; + initials else: author_full = author_full + &quot;; &quot; + last_name +&quot;, &quot;+first_name author_initials = author_initials + &quot;; &quot; + last_name + &quot;, &quot; + initials if (last_name+&quot;, &quot;+first_name).strip() not in authors: authors.append((last_name+&quot;, &quot;+first_name).strip()) all_articles.loc[ind, &quot;AF&quot;] = author_full.strip() all_articles.loc[ind, &quot;AU&quot;] = author_initials.strip() Next we have to bring the authors back into a table that VOSviewer can work with. Therefore we will create a tab delimited text file and we will also create a thesaurus of authors to use later on. all_articles.to_csv(&#39;leiden_only.txt&#39;, sep=&#39;\\t&#39;) file = open(&#39;leiden_thesaurus.txt&#39;, &#39;w+&#39;) content = &quot;\\n&quot;.join(authors) file.write(content) file.close() Next step is to create our thesaurus. Open the file ‘leiden_thesaurus.txt’ in Excel. Add a row to the top and enter the following column names: ‘Label’ in the first cell and ‘Replace by’ in the second. Next we will make a table by selecting all text and choosing ‘Table’ from the ‘Insert’ ribbon. img Sort the labels from A-Z and check if you see double entries. We will put the value we want in their ‘Replace by’ column. Be sure to also check out the names with middle names (either before the last or after the first name). img By looking at the table you most likely have noted how many names are spelled in several ways. A good indication is the number of authors mentioned in the file (almost 8 thousand), which is larger than the number of researchers we have. Difficult names such as Simon F. Portegies Zwart (double last name!) will also throw Web of Science. You will also notice there is a big problem with names that only have initials in the full name field. We might say it is easier to choose names with initials, but that strategy is more error prone once you have common names such as the Chinese Wang or Dutch De Jong. Next we filter the ‘Replace by’ column on A-Z and delete the names at the bottom we don’t replace. This is necessary to prevent them being replaced with a blank. NOTE: For the example I did not do all names due to time constraints, but see file leiden_thesaurus_replace.txt for the output I used. Export the file via ‘File’-&gt;‘Export’-&gt;‘Change File Type’-&gt;‘Text (tab delimited)’ Create a new map in VOS Viewer. Base on ‘Create a map based on bibliographic data’ -&gt; ‘Read data from bibliographic database files’ go to tab ‘Web of Science’ and choose the leiden_only.txt file. Choose the ‘Co-authorship’ map based on ‘Authors’ and use our thesaurus file. img Choose the number of documents, this may be a bit lower, as many authors will most likely drop from the list for lack of internal collaboration. e now have a very colored map with many small clusters. If you study them closely, each cluster will most likely be a research group. You may notice that some clusters from the same institute do not connect much with others (for this year): for example if I look at the chemistry institute, I see little connection between Herman Overkleeft and Sylvestre Bonnet. But Bonnet does have a strong connection with Louise van der Weerd who works on MRI and imaging techniques at LUMC. This is because Bonnet is an inorganic catalyst expert and uses techniques quite different from that of bio-organic synthesis expert Herman Overkleeft. img "],["scoring.html", "3.7 Using scoring and non-scholarly text", " 3.7 Using scoring and non-scholarly text The text visualizations in VOSviewer are well worth using in analyses that are not about scholarly literature per se. In fact you can analyze phrases in any text document, as long as the text is presented to VOSviewer in English (the algorithm is only trained in English grammar). The use of scoring files makes analysis with VOSviewer much more interesting. For example it allows us to visualize if articles contain a specific word, author or topic and see what effect this has on the mapping. One example where such an analysis may be helpful, is when you doubt the specific scholarly term for a subject (jargon). In multidisciplinary research you may find that the terms are used by different groups. By overlaying the occurrence of this term in combination with other terms, you will find out which one best suits your article. In this analysis we chose to start from a different situation in which we analyze news articles written about Leiden University and indexed in Nexis Uni. As these articles are in Dutch we had to translate them to English first with DeepL. Next we applied scoring to the different newspapers: does a local newspaper write about different subjects than a national one? Or than a religiuous one? For this analysis we have written Python code. The code can be copied by clicking the button at the right top of the code box. Go to Nexis Uni, change to ‘Advanced Search’ and search for “Universiteit Leiden” . We set the filters to include only the following newspapers: Volkskrant, Trouw, Leidsch Dagblad en Reformatorisch Dagblad for the period 23-08-2017 until 23-08-2022. img We want to export all articles as full text, preferrably in .rtf as this can be read easily by Python. We can only do this if we break down our search in smaller numbers of articles, as we are allowed to export only the first 1000 results. So filter year by year and export in these subsets by first going to ‘Tijdlijn’ in the left column and then setting the timeline so you will have less than 1000 results. img Click on the download button at the top (arrow down) and use the settings below. As downloading functions for sets of 100, you have to fill out the field ‘Volledige documenten’ to the document numbers in the set and repeat this action until all documents have been downloaded. Make sure you save all documents in the same directory. img Next we will write Python code to create text files for VOSviewer to work with. We start with creating the necessary text files and importing the libraries needed to convert the works. There is also some code to make sense of the way in which Nexis Uni describes it’s articles as we need to convert them to something that makes sense to VOSviewer. from striprtf.striprtf import rtf_to_text from datetime import date import re import os #this file contains the text we want to analyze text_file = open(&quot;all_text.txt&quot;, &quot;w+&quot;, encoding=&quot;utf-8&quot;) #this is our scoring file metadata_file = open(&quot;metadata.txt&quot;, &quot;w+&quot;, encoding=&quot;utf-8&quot;) #this function converts the date format in Nexis Uni to normal dates def get_days(date_article, corr_date): # translate dutch date into number of days # dag maand jaar weekdag date_parts = date_article.split(&quot; &quot;) day, month, year = 0, 0, 0 if len(date_parts)&gt;3: day = int(date_parts[0]) year = int(date_parts[2]) if date_parts[1]==&#39;januari&#39;: month = 1 elif date_parts[1]==&#39;februari&#39;: month=2 elif date_parts[1]==&#39;maart&#39;: month=3 elif date_parts[1]==&#39;april&#39;: month=4 elif date_parts[1]==&#39;mei&#39;: month=5 elif date_parts[1]==&#39;juni&#39;: month=6 elif date_parts[1]==&#39;juli&#39;: month=7 elif date_parts[1]==&#39;augustus&#39;: month=8 elif date_parts[1]==&#39;september&#39;: month=9 elif date_parts[1]==&#39;oktober&#39;: month=10 elif date_parts[1]==&#39;november&#39;: month=11 elif date_parts[1]==&#39;december&#39;: month=12 the_date = date(year, month, day) return (the_date-corr_date).days #this function removes some common layout words in NexisUni def remove_common(text_in): text_in = text_in.replace(&quot;Pdf&quot;, &quot;&quot;) text_in = text_in.replace(&quot;van dit document&quot;, &quot;&quot;) text_in = text_in.replace(&quot;document load date&quot;, &quot;&quot;) text_in = text_in.replace(&quot;load date&quot;, &quot;&quot;) text_in = text_in.replace(&quot;Medium&quot;, &quot;&quot;) text_in = text_in.replace(&quot;Shading&quot;, &quot;&quot;) text_in = text_in.replace(&quot;Grid&quot;, &quot;&quot;) text_in = text_in.replace(&quot;Accent&quot;, &quot;&quot;) text_in = text_in.replace(&quot;Pagina&quot;, &quot;&quot;) text_in = text_in.replace(&quot;Light&quot;, &quot;&quot;) text_in = text_in.replace(&quot;List&quot;, &quot;&quot;) text_in = text_in.replace(&quot;Colorful&quot;, &quot;&quot;) text_in = text_in.replace(&quot;Dark&quot;, &quot;&quot;) text_in = text_in.replace(&quot;Subtle&quot;, &quot;&quot;) text_in = text_in.replace(&quot;Emphasis&quot;, &quot;&quot;) text_in = text_in.replace(&quot;Intense&quot;, &quot;&quot;) return text_in The NexisUni export is quite uniform. We can readout the contents by checking all files in the directory we saved our rtf’s. Each file has metadata describing the article specifically structured (but a bit difficult to read for a script), something you will discover while looking at some examples. The title for example, is always after the url, and after the title we first have the news outlet and then the date. The document text is in between the line ‘Body’ and ‘End of document’. for article in os.listdir(&#39;articles_nexisuni&#39;): #read all files in the directory articles_nexisuni if article[:2]!=&quot;~$&quot;: # skip temporary files. news_article = open(os.path.join(&#39;articles_nexisuni&#39;, article), &#39;r&#39;, encoding=&quot;utf-8&quot;) i = 0 next_section = &#39; &#39; title = &#39;&#39; newspaper = &#39;&#39; article_date = &#39;&#39; body = &#39;&#39; for line in news_article.readlines(): i+=1 line=rtf_to_text(line, &#39;ignore&#39;) line = line.strip() if len(line)&gt;0 and line!=&quot;&quot;: if line[:6]==&quot;https:&quot; and len(title)&lt;=0: next_section = &#39;title&#39; elif next_section==&#39;title&#39;: if not (line==&quot;de Volkskrant&quot; or line==&#39;Trouw&#39; or line==&#39;Leidsch Dagblad&#39; or line==&quot;Reformatorisch Dagblad&quot;): title += line else: newspaper = line next_section = &#39;article_date&#39; elif next_section==&#39;article_date&#39;: article_date = get_days(line, date(2017,8,23)) #we calculate the number of days since the first publication in our set next_section = &#39;wait&#39; elif next_section==&#39;wait&#39; and line[:4]==&quot;Body&quot;: next_section = &#39;body&#39; elif next_section==&#39;body&#39; and not line[:15]==&quot;End of Document&quot;: body += line + &quot; &quot; + &#39;\\n&#39; elif next_section==&#39;body&#39; and line[:15]==&quot;End of Document&quot;: next_section=&#39;end&#39; #We have to strip all information from the body pattern = re.compile(r&#39;[\\n\\r]+&#39;) #r&#39;[^\\w\\.,;: ]+&#39;) body = title + &quot; &quot; + body body = re.sub(pattern, &#39; &#39;, body) body = remove_common(body) # to remove some common nexis uni terms text_file.write(body+&#39;\\n&#39;) volkskrant, trouw, leidsch_dagblad, reformatorisch_dagblad, voermans = 0,0,0,0,0 if newspaper ==&#39;de Volkskrant&#39;: volkskrant=1 elif newspaper==&#39;Trouw&#39;: trouw=1 elif newspaper==&#39;Leidsch Dagblad&#39;: leidsch_dagblad=1 elif newspaper==&#39;Reformatorisch Dagblad&#39;: reformatorisch_dagblad=1 # let&#39;s do an extra check to see if Wim Voermans is involved if re.search(&quot;(?i)voermans&quot;, body, re.IGNORECASE): voermans=1 metadata_file.write(f&#39;\\n{article_date}\\t{volkskrant}\\t{trouw}\\t{leidsch_dagblad}\\t{reformatorisch_dagblad}\\t{voermans}&#39;) # next we save and close the files metadata_file.close() text_file.close() After the script has worked through all the files, we have a text file (all_text.txt) and a scoring file (metadata.txt). Entering these into VOSviewer would give unusable results as the VOSviewer algorithm can only work with English phrases. Therefore we have to translate the text. In theory translation can be done in several ways, for example by using Google Translate API. However, the sheer size of the text (we are indexing fulltext!) means this would cost us upwards of 100 dollars. A cheaper way is to take a test or full subscription to DeepL and convert text files. You can take out a DeepL trial or subscription at https://www.deepl.com/ (for smaller searches this may work well without subscription). For DeepL the maximum text size is 1 Mb, so our first step is to split the text files: def split_into_files(text_size_limit=800000): text_size_counter = 0 file_number = 0 with open(&quot;all_text.txt&quot;, encoding=&quot;utf-8&quot;) as f: lines = f.readlines() current_file = open(&quot;all_text_&quot;+str(file_number)+&quot;.txt&quot;, &quot;w+&quot;, encoding=&quot;utf-8&quot;) for line in lines: text_size_counter += len(line)+2 #add linebreaks as character if text_size_counter &gt; text_size_limit: current_file.close() file_number += 1 current_file = open(&quot;all_text_&quot;+str(file_number)+&quot;.txt&quot;, &quot;w+&quot;, encoding=&quot;utf-8&quot;) text_size_counter = len(line)+2 current_file.write(line) current_file.close() split_into_files() The split files can be uploaded to DeepL and after that we can stitch the results back to one big file (be sure to keep the same order of the files, otherwise the scoring file will be off). We can do this with the following script: def combine_files(name=&quot;all_text_&quot;): # walk the os_path file_names_found = {} full_translation = open(&quot;all_text_translated.txt&quot;, &quot;w+&quot;, encoding=&quot;utf-8&quot;) for x in os.listdir(): print(x) if x.find(name) &gt;= 0: pattern = re.compile(&#39;_([0-9]+) &#39;) pos = pattern.search(x) if pos: print(&quot;pos: &quot;+ pos.group(1)) file_names_found[int(pos.group(1))] = x # start retrieving files for i in range(0, len(file_names_found)): with open(file_names_found[i], encoding=&quot;utf-8&quot;) as f: for line in f.readlines(): if line.strip() != &quot;&quot;: #remove empty last lines full_translation.write(line) f.close() full_translation.close() combine_files() Now we can use VOSviewer to create a plot with multiple overlays. Choose ‘Create’-&gt;‘Create a map based on text data’-&gt;‘Read data from Vos Viewer files’. Use the first file box for the text file and the second one for the scoring file. img In the next window we choose binary counting. In this case we don’t use a thesaurus, but if you want to ensure that certain synonyms are grouped together, you can use a thesaurus. When asked for a minimum number of terms I usually select to keep around the 1000-2000 results. In this case this means a term should occur at least 24 times. Next we finish and create our map. img Looking at our map, I get the idea that some clusters are overlapping too much. In red, for example, I see both students and political parties mentioned. Therefore it may be better to increase the resolution and create more clusters. To do this I have entered 1.2 in the box for resolution (Analysis tab on the left side, see Clustering). Press ‘Update clustering’ to create the new visualization. img The clusters are know separated in a more meaningful way. A quick look clockwise: blue (board, student, spokesperson, Leiden) seems to be about university affairs red (science, space, technology, computer, data) about scholarly output in the exact sciences green (Century, church, art, museum, visitor) this may well be connected to the Leiden past as we have had an anniversary during the analysis. yellow (Europe, leader, war, Russia) about international affairs orange (police, security, victim, court) about justice purple (government, party, citizen, politician) about politics light blue in the middle about family affairs/people Now we go to the tab ’Overlay visualization’at the top of VOSviewer. On the right we can choose what visualization we want. By default it uses the first score, in our case number of days since the start of the newsline. Under scores you can select the scoring you want to use, fo example our news source Volkskrant. img Let’s switch to the scoring for ‘Wim Voermans’. Voermans is a well know Leiden professor of consitutional and administrative law. He is regularly asked for comments on state affairs, for example during the elections or for the nitrogen emission rights that have a large impact on the functioning of our government. The visualization reflects this. These topics (cabinet, council, debate, nitrogen) are yellow in the visualization (often occur in combination with Wim Voermans as you can see in the scale at the bottom). The size of the dot of each cluster, is an indication whether the topic is mentioned a lot within all documents. img For the newspapers ‘Trouw’, ‘De Volkskrant’, ‘Leidsch Dagblad’ and ‘Reformatorisch Dagblad’. These newspapers have been selected as they all have a different profile. The visualization gives information on how they differ from the average. Leidsch Dagblad is a local newspaper. In the visualization we can see it focuses (yellow). You can see it overlaps mainly with the university affairs cluster with words like campus being mentioned a lot) we saw earlier. There is not that much focus on the other topics such as science or state affairs. If we hover over the word ‘campus’ you will see a score in the bottom bar for Leidsch Dagblad of 0.74. This means that for the 86 occurrences of ‘campus’ in the set, 74 per cent - 64 - times it was in Leidsch Dagblad. So even though the number of occurrences is relatively small, the use of the term is quite unique for Leidsch Dagblad thus it has a specific focus here. (If all newspapers found it of equal interest, it would have been around 0.2-0.3 and blue) img img De Volkskrant is a big national newspaper, a bit elitist and it is well known for politics and science reporting. You can immediately see that within this set Volkskrant is dominant in reporting about our observatory, while the university affairs are less important. (Be aware that Leidsch Dagblad has a dominance in university affairs, but even then, Volkskrant scores 0.13 while we expected 0.25 according to the table below). img Trouw is a modern christian newspaper well known for reporting science and high quality journalism. It’s a bit of a generalist in this set. It’s not doing that well in astronomy which is a subject that may question belief. Within the set its focus is slightly more towards politics, security and international relations. img Reformatorisch Dagblad is a very traditional christian newspaper. Judging by the scale, it is pretty average in most subjects. Within the set it has a focus on for example words such as god (0.42) and church (0.39). This is remarkable as the number of articles from this source is lower than from the other sources. img Source # documents Average De Volkskrant 794 0.25 Leidsch Dagblad 1637 0.49 Reformatorisch Dagblad 321 0.10 Trouw 589 0.18 "],["sharing-your-results.html", "Chapter 4 Sharing your results", " Chapter 4 Sharing your results Visualizations from VOSviewer can be shared as image or as fully functional iframe on your website. However, visualizations should always be accompanied by some explanations on how to read them. In this chapter we give basic advise on sharing your data. 4.0.1 Basic information on the analysis It is always important to show how you created your visualization. What search is it based upon, why did you choose these parameters, et cetera. By noting down this information you also help yourself if you want to make adjustments later (re-search). Is is good practice to say in the comments what you were trying to accomplish, so other experts may help you refine your query if needed. You can use a template for this: Search Query Purpose What research question are you trying to solve with this analysis? Source For example: Web of Science Date For example: 2023-01-23 Search string For example: ’“machine learn*” OR “Artificial Intelligence” Filters inclusion For example: Document Type=‘Journal Article’, Time=‘2018-now’ Filters exclusion For example: Journal=‘PLoS One’ Number of results # Comments Any other search specifics and/or the reason for this specific database and query 4.0.2 Sharing a visualization: as image The screenshot function literally gives you the ability to make a screenshot of the current view (so the zoomed in or out image) of VOSviewer. It is therefore important to zoom in and scroll to the right position for the visualization you want to show. You can use the mouse or the buttons at the right top of the viewer to do this. img If the labels on your visualization are overlapping, there is a trick to change the visualization a little. For this go to the left column, choose the ‘Analysis’ tab. Uncheck the default values checkbox for the Layout and set attraction to 1 and repulsion to 0. Don’t forget to update the layout! (and change the viewer again if necessary) img Depending on where you want to share, you might need a bigger figure (for print for example) than your screen offers. In the left column go to the ‘File’ tab. Click on the right part of the ‘Screenshot’ button and choose options. Here you can choose how you want to export your image. 200 per cent scaling for example, means the image has width*height=2*2=4 times the resolution from the one on your screen. img To save the image, click the screenshot button. 4.0.3 Sharing an interactive visualization VOSviewer also allows you to share your visualization as interactive element on websites. For this you need to upload the visualization to a cloud service such as Google Drive and then add code for an iframe to your website. In the left menu of VOSviewer choose the ‘File’ tab. Right clicking the Share button gives you the ability to upload to Google Drive, Dropbox or the university supported Microsoft OneDrive. In this example I choose Onedrive. The application will ask you to login or confirm. Once this is done the file is automatically uploaded and we are forwarded to the basic analysis of our VOSviewer screen (note overlays ore not yet possible). In the upper right corner is a share icon. Click it and you will find several options for sharing. The iframe gives you the possibility to embed a visualization on your website. If your website does not support iframes, a link is another option. As iframe: knitr::include_url(&quot;https://tinyurl.com/2m4d4n7d&quot;) 4.0.4 Explaining your visualization People with some expertise in the field can usually follow more or less what the visualization is about once they know the purpose and input. However, it is strongly recommended to explain the visualization. In order to explain the visualization, it usually helps to mention the large clusters. What are they? can you explain them? What do they tell you about your initial research question (as mentioned in the first step). "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
